{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1685107221076
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: azure-ai-ml\r\n",
            "Version: 1.5.0\r\n",
            "Summary: Microsoft Azure Machine Learning Client Library for Python\r\n",
            "Home-page: https://github.com/Azure/azure-sdk-for-python\r\n",
            "Author: Microsoft Corporation\r\n",
            "Author-email: azuresdkengsysadmins@microsoft.com\r\n",
            "License: MIT License\r\n",
            "Location: /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages\r\n",
            "Requires: azure-common, azure-core, azure-mgmt-core, azure-storage-blob, azure-storage-file-datalake, azure-storage-file-share, colorama, isodate, jsonschema, marshmallow, msrest, opencensus-ext-azure, pydash, pyjwt, pyyaml, strictyaml, tqdm, typing-extensions\r\n",
            "Required-by: \r\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip show azure-ai-ml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1685107227062
        }
      },
      "outputs": [],
      "source": [
        "# enter details of your AML workspace\n",
        "subscription_id = \"YOUR SUBSCRIPTION ID HERE\"\n",
        "resource_group = \"rg-churn-pred-proj\"\n",
        "workspace = \"churn-pred-proj\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1685107234025
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "\n",
        "# get a handle to the workspace\n",
        "ml_client = MLClient(\n",
        "    DefaultAzureCredential(), subscription_id, resource_group, workspace)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Creating a Data Asset\n",
        "This is the data we have downloaded form hugging face website and will be using for model development."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# List Data Stores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1685107239610
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "workspaceworkingdirectory\n",
            "workspaceartifactstore\n",
            "workspacefilestore\n",
            "workspaceblobstore\n"
          ]
        }
      ],
      "source": [
        "stores = ml_client.datastores.list()\n",
        "for ds_name in stores:\n",
        "    print(ds_name.name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1685107245373
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32mUploading churn.csv\u001b[32m (< 1 MB): 100%|██████████| 970k/970k [00:00<00:00, 23.1MB/s]\n",
            "\u001b[39m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data asset created. Name: telco-churn, version: 2023.05.26.132043\n"
          ]
        }
      ],
      "source": [
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "import time\n",
        "\n",
        "my_path = \"./data/churn.csv\"\n",
        "# web_path = \"https://huggingface.co/datasets/scikit-learn/churn-prediction/blob/main/dataset.csv\"\n",
        "# set the version number of the data asset to the current UTC time\n",
        "v1 = time.strftime(\"%Y.%m.%d.%H%M%S\", time.gmtime())\n",
        "\n",
        "churn_data = Data(\n",
        "    name=\"telco-churn\",\n",
        "    version=v1,\n",
        "    description=\"Churning customers of a telecommunication company\",\n",
        "    path=my_path,\n",
        "    type=AssetTypes.URI_FILE,\n",
        "    tags={\"source_type\": \"web\", \"source\": \"Hugging Face\"},\n",
        ")\n",
        "\n",
        "# create data asset\n",
        "ml_client.data.create_or_update(churn_data)\n",
        "\n",
        "print(f\"Data asset created. Name: {churn_data.name}, version: {churn_data.version}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Access Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -U azureml-fsspec"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Check to see if we have the data or not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1685107269439
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data asset URI: azureml://subscriptions/733ee2ff-5a9c-42a2-8242-b8a500eb9f53/resourcegroups/rg-churn-pred-proj/workspaces/churn-pred-proj/datastores/workspaceblobstore/paths/LocalUpload/980708968c362ca31f4225d8576b9cab/churn.csv\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customerID</th>\n",
              "      <th>gender</th>\n",
              "      <th>SeniorCitizen</th>\n",
              "      <th>Partner</th>\n",
              "      <th>Dependents</th>\n",
              "      <th>tenure</th>\n",
              "      <th>PhoneService</th>\n",
              "      <th>MultipleLines</th>\n",
              "      <th>InternetService</th>\n",
              "      <th>OnlineSecurity</th>\n",
              "      <th>...</th>\n",
              "      <th>DeviceProtection</th>\n",
              "      <th>TechSupport</th>\n",
              "      <th>StreamingTV</th>\n",
              "      <th>StreamingMovies</th>\n",
              "      <th>Contract</th>\n",
              "      <th>PaperlessBilling</th>\n",
              "      <th>PaymentMethod</th>\n",
              "      <th>MonthlyCharges</th>\n",
              "      <th>TotalCharges</th>\n",
              "      <th>Churn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7590-VHVEG</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>1</td>\n",
              "      <td>No</td>\n",
              "      <td>No phone service</td>\n",
              "      <td>DSL</td>\n",
              "      <td>No</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Electronic check</td>\n",
              "      <td>29.85</td>\n",
              "      <td>29.85</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5575-GNVDE</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>34</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>One year</td>\n",
              "      <td>No</td>\n",
              "      <td>Mailed check</td>\n",
              "      <td>56.95</td>\n",
              "      <td>1889.5</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3668-QPYBK</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>2</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Mailed check</td>\n",
              "      <td>53.85</td>\n",
              "      <td>108.15</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7795-CFOCW</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>45</td>\n",
              "      <td>No</td>\n",
              "      <td>No phone service</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>One year</td>\n",
              "      <td>No</td>\n",
              "      <td>Bank transfer (automatic)</td>\n",
              "      <td>42.30</td>\n",
              "      <td>1840.75</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9237-HQITU</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>2</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Fiber optic</td>\n",
              "      <td>No</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Electronic check</td>\n",
              "      <td>70.70</td>\n",
              "      <td>151.65</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService   \n",
              "0  7590-VHVEG  Female              0     Yes         No       1           No  \\\n",
              "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
              "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
              "3  7795-CFOCW    Male              0      No         No      45           No   \n",
              "4  9237-HQITU  Female              0      No         No       2          Yes   \n",
              "\n",
              "      MultipleLines InternetService OnlineSecurity  ... DeviceProtection   \n",
              "0  No phone service             DSL             No  ...               No  \\\n",
              "1                No             DSL            Yes  ...              Yes   \n",
              "2                No             DSL            Yes  ...               No   \n",
              "3  No phone service             DSL            Yes  ...              Yes   \n",
              "4                No     Fiber optic             No  ...               No   \n",
              "\n",
              "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling   \n",
              "0          No          No              No  Month-to-month              Yes  \\\n",
              "1          No          No              No        One year               No   \n",
              "2          No          No              No  Month-to-month              Yes   \n",
              "3         Yes          No              No        One year               No   \n",
              "4          No          No              No  Month-to-month              Yes   \n",
              "\n",
              "               PaymentMethod MonthlyCharges  TotalCharges Churn  \n",
              "0           Electronic check          29.85         29.85    No  \n",
              "1               Mailed check          56.95        1889.5    No  \n",
              "2               Mailed check          53.85        108.15   Yes  \n",
              "3  Bank transfer (automatic)          42.30       1840.75    No  \n",
              "4           Electronic check          70.70        151.65   Yes  \n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# get a handle of the data asset and print the URI\n",
        "data_asset = ml_client.data.get(name=\"telco-churn\", version=v1)\n",
        "print(f\"Data asset URI: {data_asset.path}\")\n",
        "\n",
        "# read into pandas - note that you will see 2 headers in your data frame - that is ok, for now\n",
        "\n",
        "df = pd.read_csv(data_asset.path)\n",
        "df.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Compute Cluster for Pipeline\n",
        "\n",
        "Once you run the cell, wiat and check under compute to see if the compute has been created successfully before proceeding. You also get a green notification too if you have the default settings on. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1685107276323
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating a new cpu compute target...\n",
            "AMLCompute with name cpu-cluster is created, the compute size is STANDARD_DS3_V2\n"
          ]
        }
      ],
      "source": [
        "from azure.ai.ml.entities import AmlCompute\n",
        "\n",
        "cpu_compute_target = \"cpu-cluster\"\n",
        "\n",
        "try:\n",
        "    # let's see if the compute target already exists\n",
        "    cpu_cluster = ml_client.compute.get(cpu_compute_target)\n",
        "    print(\n",
        "        f\"You already have a cluster named {cpu_compute_target}, we'll reuse it as is.\"\n",
        "    )\n",
        "\n",
        "except Exception:\n",
        "    print(\"Creating a new cpu compute target...\")\n",
        "\n",
        "    # Let's create the Azure ML compute object with the intended parameters\n",
        "    cpu_cluster = AmlCompute(\n",
        "        # Name assigned to the compute cluster\n",
        "        name=\"cpu-cluster\",\n",
        "        # Azure ML Compute is the on-demand VM service\n",
        "        type=\"amlcompute\",\n",
        "        # VM Family\n",
        "        size=\"STANDARD_DS3_V2\",\n",
        "        # Minimum running nodes when there is no job running\n",
        "        min_instances=0,\n",
        "        # Nodes in cluster\n",
        "        max_instances=4,\n",
        "        # How many seconds will the node running after the job termination\n",
        "        idle_time_before_scale_down=180,\n",
        "        # Dedicated or LowPriority. The latter is cheaper but there is a chance of job termination\n",
        "        tier=\"Dedicated\",\n",
        "    )\n",
        "    \n",
        "    print(\n",
        "    f\"AMLCompute with name {cpu_cluster.name} is created, the compute size is {cpu_cluster.size}\"\n",
        "    )\n",
        "\n",
        "    # Now, we pass the object to MLClient's create_or_update method\n",
        "    cpu_cluster = ml_client.begin_create_or_update(cpu_cluster)\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pipeline job environment creation\n",
        "Refresh the file explorer to make sure the directory is created"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1685107280861
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "dependencies_dir = \"./dependencies\"\n",
        "os.makedirs(dependencies_dir, exist_ok=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creating conda yaml file for in the dependencies directory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing ./dependencies/conda.yaml\n"
          ]
        }
      ],
      "source": [
        "%%writefile {dependencies_dir}/conda.yaml\n",
        "channels:\n",
        "  - conda-forge\n",
        "dependencies:\n",
        "  - python=3.8\n",
        "  - numpy=1.23.5\n",
        "  - pip=22.3.1\n",
        "  - scikit-learn=1.2.2\n",
        "  - pandas=1.5.3\n",
        "  - matplotlib=3.7.1\n",
        "  - imbalanced-learn=0.10.1\n",
        "  - pip:\n",
        "      - mlflow==1.26.1\n",
        "      - azureml-mlflow==1.42.0\n",
        "      - xgboost==1.7.5\n",
        "name: churn-env"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Environment\n",
        "This can take around 5-10 minutes. Check the environment under the environment tab (custom environments). It changes from running to successful if everything is correct. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1685107326140
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment with name Churn-Proj-scikit-learn is registered to workspace, the environment version is 0.1.1\n"
          ]
        }
      ],
      "source": [
        "from azure.ai.ml.entities import Environment\n",
        "\n",
        "custom_env_name = \"Churn-Proj-scikit-learn\"\n",
        "\n",
        "pipeline_job_env = Environment(\n",
        "    name=custom_env_name,\n",
        "    description=\"Custom environment for Customer Churn pipeline\",\n",
        "    tags={\"scikit-learn\": \"1.2.2\"},\n",
        "    conda_file=os.path.join(dependencies_dir, \"conda.yaml\"),\n",
        "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\",\n",
        "    version=\"0.1.1\",\n",
        ")\n",
        "pipeline_job_env = ml_client.environments.create_or_update(pipeline_job_env)\n",
        "\n",
        "print(\n",
        "    f\"Environment with name {pipeline_job_env.name} is registered to workspace, the environment version is {pipeline_job_env.version}\"\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Creating the environment takes around 5-10 minutes depending on the packages. <mark>DO NOT PROCEED BEFORE THE ENVIRONMENT IS MARKED AS SUCCESSFUL. </mark>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Building Pipeline\n",
        "\n",
        "We require two components, Each component requires the python script (cells will write this to the appropriate file) and the yaml file.\n",
        "\n",
        "## Component 1: Data Prep\n",
        "This envolves missing vlaue recification, dropping some columns, encoding and scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1685108008805
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "src folder created\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# create a folder for the script files\n",
        "script_folder = 'src'\n",
        "os.makedirs(script_folder, exist_ok=True)\n",
        "print(script_folder, 'folder created')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "prep-data.py script\n",
        "This is the preparation component of the pipeline, some data cleaning, ecnoding and scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing src/prep-data.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile $script_folder/prep-data.py\n",
        "\n",
        "# import libraries\n",
        "import argparse\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "def main(args):\n",
        "    # read data\n",
        "    print('Reading data ...')\n",
        "    df = get_data(args.input_data)\n",
        "\n",
        "    print('Cleaning data ...')\n",
        "    cleaned_data = clean_data(df)\n",
        "\n",
        "    print('Encoding data ...')\n",
        "    encoded_data = encode_data(cleaned_data)\n",
        "\n",
        "    print('Normalizing data ...')\n",
        "    normalized_data = normalize_data(encoded_data)\n",
        "\n",
        "    output_df = normalized_data.to_csv((Path(args.output_data) / \"churn_prepped.csv\"), index = False)\n",
        "\n",
        "\n",
        "def parse_args():\n",
        "    # setup arg parser\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    # add arguments\n",
        "    parser.add_argument(\"--input_data\", dest='input_data',\n",
        "                        type=str)\n",
        "    parser.add_argument(\"--output_data\", dest='output_data',\n",
        "                        type=str)\n",
        "\n",
        "    # parse args\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # return args\n",
        "    return args\n",
        "\n",
        "# function that reads the data\n",
        "def get_data(path):\n",
        "    df = pd.read_csv(path)\n",
        "\n",
        "    # Count the rows and print the result\n",
        "    row_count = (len(df))\n",
        "    print('Preparing {} rows of data'.format(row_count))\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# function that removes useless values and imputes missing ones\n",
        "def clean_data(df):\n",
        "    # Column TotalCharges is a string, have to convert to numeric\n",
        "    df.TotalCharges = df.TotalCharges.apply([lambda x: float(x) if x!= ' ' else x]) # make float if value exists\n",
        "    mean = pd.to_numeric(df.TotalCharges, errors='coerce').mean()\n",
        "    df.TotalCharges = df.TotalCharges.apply([lambda x: mean if x == ' ' else x ]) # replace ' ' with mean of this column\n",
        "\n",
        "    # Drop useless columns (high cardinality and low correlation clumns - based on the ANOVA test done in EDA)\n",
        "    df.drop(['customerID', 'gender','PhoneService', 'MultipleLines',\n",
        "            'InternetService','StreamingTV', 'StreamingMovies'], axis = 1, inplace=True)\n",
        "    \n",
        "    return df   \n",
        "\n",
        "# Function that encodes the data\n",
        "def encode_data(df):\n",
        "    cat_cols = ['Partner','Dependents','OnlineSecurity','OnlineBackup',\n",
        "    \t        'DeviceProtection','TechSupport','PaperlessBilling',\n",
        "                'Contract', 'PaymentMethod'] #categorica columns\n",
        "\n",
        "    # Encode categorical columns\n",
        "    ord_enc = OrdinalEncoder()\n",
        "    df[cat_cols] = ord_enc.fit_transform(df[cat_cols]).copy() \n",
        "    # Mapping the target (Churn column)\n",
        "    lb = LabelEncoder()\n",
        "    df['Churn'] = lb.fit_transform(df['Churn'])\n",
        "\n",
        "    return df\n",
        "\n",
        "# function that normalizes the data\n",
        "def normalize_data(df):\n",
        "    # Define Scaler\n",
        "    mms = MinMaxScaler() # Normalisation using min max scaler\n",
        "    df['tenure'] = mms.fit_transform(df[['tenure']])\n",
        "    df['MonthlyCharges'] = mms.fit_transform(df[['MonthlyCharges']])\n",
        "    df['TotalCharges'] = mms.fit_transform(df[['TotalCharges']])\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# run script\n",
        "if __name__ == \"__main__\":\n",
        "    # add space in logs\n",
        "    print(\"\\n\\n\")\n",
        "    print(\"*\" * 60)\n",
        "\n",
        "    # parse args\n",
        "    args = parse_args()\n",
        "\n",
        "    # run main function\n",
        "    main(args)\n",
        "\n",
        "    # add space in logs\n",
        "    print(\"*\" * 60)\n",
        "    print(\"\\n\\n\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Preparing YAML file for prep-data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing prep-data.yml\n"
          ]
        }
      ],
      "source": [
        "%%writefile prep-data.yml\n",
        "$schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json\n",
        "name: prep_data\n",
        "display_name: Prepare training data imbalanced sampling\n",
        "version: 1\n",
        "type: command\n",
        "inputs:\n",
        "  input_data: \n",
        "    type: uri_file\n",
        "outputs:\n",
        "  output_data:\n",
        "    type: uri_folder\n",
        "code: ./src\n",
        "environment: azureml:Churn-Proj-scikit-learn:0.1.1\n",
        "command: >-\n",
        "  python prep-data.py \n",
        "  --input_data ${{inputs.input_data}}\n",
        "  --output_data ${{outputs.output_data}}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Component 2: Train and Evaluate Model\n",
        "We use mlflow to keep track of the training"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "train-model.py script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing src/train-model.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile $script_folder/train-model.py\n",
        "\n",
        "import mlflow\n",
        "from mlflow.models.signature import ModelSignature\n",
        "from mlflow.types.schema import Schema, ColSpec\n",
        "\n",
        "import glob\n",
        "import argparse\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import RocCurveDisplay\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "def main(args):\n",
        "\n",
        "    mlflow.start_run()\n",
        "\n",
        "    # enable autologging\n",
        "    # mlflow.autolog()\n",
        "\n",
        "    # read data\n",
        "    df = get_data(args.training_data)\n",
        "\n",
        "    # split data\n",
        "    X_train, X_test, y_train, y_test = split_data(df)\n",
        "\n",
        "    # train model\n",
        "    model = train(args.learning_rate, args.max_depth , X_train, y_train)\n",
        "\n",
        "    # evaluate model\n",
        "    evaluate(model, X_test, y_test)\n",
        "\n",
        "    mlflow.end_run()\n",
        "\n",
        "\n",
        "# function that reads the data\n",
        "def get_data(data_path):\n",
        "\n",
        "    all_files = glob.glob(data_path + \"/*.csv\")\n",
        "    df = pd.concat((pd.read_csv(f) for f in all_files), sort=False)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# function that splits the data - uses SMOTE as data unbalanced.\n",
        "def split_data(df):\n",
        "    print(\"Splitting data...\")\n",
        "\n",
        "    oversample = SMOTE(sampling_strategy=1) # same sample size\n",
        "    f1 = df.iloc[:,:13].values\n",
        "    t1 = df.iloc[:,13].values\n",
        "    f1, t1 = oversample.fit_resample(f1, t1)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(f1, t1, test_size=0.20, random_state=0)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "\n",
        "# Function that trains the model, learning rate and max depth are nput args\n",
        "def train(learning_rate, max_depth, X_train, y_train):\n",
        "    mlflow.log_param(\"learning_rate\", learning_rate)\n",
        "    mlflow.log_param(\"max_depth\", max_depth)\n",
        "\n",
        "    model = XGBClassifier(learning_rate = learning_rate, max_depth = int(max_depth), n_estimators = 1000)\n",
        "\n",
        "    model.fit(X_train,y_train)\n",
        "    return model\n",
        "\n",
        "\n",
        "# Function that evaluates the model\n",
        "def evaluate(model,X_test,y_test):\n",
        "    # calculate accuracy\n",
        "    y_hat = model.predict(X_test)\n",
        "    acc = np.average(y_hat == y_test)\n",
        "    print('Accuracy:', acc)\n",
        "\n",
        "    # calculate AUC\n",
        "    y_scores = model.predict_proba(X_test)\n",
        "    auc = roc_auc_score(y_test,y_scores[:,1])\n",
        "    print('AUC: ' + str(auc))\n",
        "\n",
        "    params = {\n",
        "        \"Accuracy\": acc,\n",
        "        \"AUC\": auc,       \n",
        "        }\n",
        "\n",
        "    mlflow.log_metrics(params)\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = ConfusionMatrixDisplay.from_predictions(y_test,y_hat, normalize = 'true', cmap = 'Blues')\n",
        "    #plt.savefig(\"Confusion-Matrix.png\") \n",
        "    mlflow.log_figure(cm.figure_, \"Confusion-Matrix.png\")\n",
        "\n",
        "    # plot ROC curve\n",
        "    roc = RocCurveDisplay.from_predictions(y_test,y_hat)\n",
        "    # Plot the diagonal 50% line\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    # Plot the FPR and TPR achieved by our model\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curve')\n",
        "    #plt.savefig(\"ROC-Curve.png\") \n",
        "    mlflow.log_figure(roc.figure_, \"ROC-Curve.png\")   \n",
        "\n",
        "    # Classification Report\n",
        "    print(classification_report(y_test,y_hat))\n",
        "\n",
        "    mlflow.log_text(classification_report(y_test,y_hat), \"clf_report.txt\")\n",
        "\n",
        "\n",
        "    input_schema = Schema(\n",
        "        [\n",
        "            ColSpec(\"integer\", \"SeniorCitizen\"),\n",
        "            ColSpec(\"double\", \"Partner\"),\n",
        "            ColSpec(\"double\", \"Dependents\"),\n",
        "            ColSpec(\"double\", \"tenure\"),\n",
        "            ColSpec(\"double\", \"OnlineSecurity\"),\n",
        "            ColSpec(\"double\", \"OnlineBackup\"),\n",
        "            ColSpec(\"double\", \"DeviceProtection\"),\n",
        "            ColSpec(\"double\", \"TechSupport\"),\n",
        "            ColSpec(\"double\", \"Contract\"),\n",
        "            ColSpec(\"double\", \"PaperlessBilling\"),\n",
        "            ColSpec(\"double\", \"PaymentMethod\"),\n",
        "            ColSpec(\"double\", \"MonthlyCharges\"),\n",
        "            ColSpec(\"double\", \"TotalCharges\"),\n",
        "        ]\n",
        "    )\n",
        "    output_schema = Schema([ColSpec(\"integer\")])\n",
        "    signature = ModelSignature(inputs=input_schema, outputs=output_schema)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Save Model\n",
        "    mlflow.xgboost.log_model(model, args.model_output, signature=signature)\n",
        "\n",
        "\n",
        "def parse_args():\n",
        "    # setup arg parser\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    # add arguments\n",
        "    parser.add_argument(\"--training_data\", dest='training_data',\n",
        "                        type=str)\n",
        "    parser.add_argument(\"--learning_rate\", dest='learning_rate',\n",
        "                        type=float, default=0.01)\n",
        "    parser.add_argument(\"--max_depth\", dest='max_depth',\n",
        "                        type=int, default=3)\n",
        "    parser.add_argument(\"--model_output\", dest='model_output',\n",
        "                        type=str)\n",
        "\n",
        "    # parse args\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # return args\n",
        "    return args\n",
        "\n",
        "# run script\n",
        "if __name__ == \"__main__\":\n",
        "    # add space in logs\n",
        "    print(\"\\n\\n\")\n",
        "    print(\"*\" * 60)\n",
        "\n",
        "    # parse args\n",
        "    args = parse_args()\n",
        "\n",
        "    # run main function\n",
        "    main(args)\n",
        "\n",
        "    # add space in logs\n",
        "    print(\"*\" * 60)\n",
        "    print(\"\\n\\n\")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "train-model.YAML file "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing train-model.yml\n"
          ]
        }
      ],
      "source": [
        "%%writefile train-model.yml\n",
        "$schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json\n",
        "name: train_model\n",
        "display_name: Train an XGBoost classifier model\n",
        "version: 1\n",
        "type: command\n",
        "inputs:\n",
        "  training_data: \n",
        "    type: uri_folder\n",
        "  learning_rate:\n",
        "    type: number\n",
        "    default: 0.01\n",
        "  max_depth:\n",
        "    type: integer\n",
        "    default: 3\n",
        "outputs:\n",
        "  model_output:\n",
        "    type: mlflow_model\n",
        "code: ./src\n",
        "environment: azureml:Churn-Proj-scikit-learn:0.1.1\n",
        "command: >-\n",
        "  python train-model.py \n",
        "  --training_data ${{inputs.training_data}} \n",
        "  --learning_rate ${{inputs.learning_rate}}\n",
        "  --max_depth ${{inputs.max_depth}}\n",
        "  --model_output ${{outputs.model_output}} "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Components"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1685108061772
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml import load_component\n",
        "parent_dir = \"\"\n",
        "\n",
        "prep_data = load_component(source=parent_dir + \"./prep-data.yml\")\n",
        "train_XGBoost = load_component(source=parent_dir + \"./train-model.yml\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1685108063657
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml import Input\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "from azure.ai.ml.dsl import pipeline\n",
        "\n",
        "@pipeline()\n",
        "def customer_churn_classification(pipeline_job_input):\n",
        "    clean_data = prep_data(input_data=pipeline_job_input)\n",
        "    train_model = train_XGBoost(training_data=clean_data.outputs.output_data)\n",
        "\n",
        "    return {\n",
        "        \"pipeline_job_transformed_data\": clean_data.outputs.output_data,\n",
        "        \"pipeline_job_trained_model\": train_model.outputs.model_output,\n",
        "    }\n",
        "\n",
        "pipeline_job = customer_churn_classification(Input(type=AssetTypes.URI_FILE, path= data_asset.path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1685108066761
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "display_name: customer_churn_classification\n",
            "type: pipeline\n",
            "inputs:\n",
            "  pipeline_job_input:\n",
            "    type: uri_file\n",
            "    path: azureml://subscriptions/733ee2ff-5a9c-42a2-8242-b8a500eb9f53/resourcegroups/rg-churn-pred-proj/workspaces/churn-pred-proj/datastores/workspaceblobstore/paths/LocalUpload/980708968c362ca31f4225d8576b9cab/churn.csv\n",
            "outputs:\n",
            "  pipeline_job_transformed_data:\n",
            "    type: uri_folder\n",
            "  pipeline_job_trained_model:\n",
            "    type: mlflow_model\n",
            "jobs:\n",
            "  clean_data:\n",
            "    type: command\n",
            "    inputs:\n",
            "      input_data:\n",
            "        path: ${{parent.inputs.pipeline_job_input}}\n",
            "    outputs:\n",
            "      output_data: ${{parent.outputs.pipeline_job_transformed_data}}\n",
            "    component:\n",
            "      $schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json\n",
            "      name: prep_data\n",
            "      version: '1'\n",
            "      display_name: Prepare training data imbalanced sampling\n",
            "      type: command\n",
            "      inputs:\n",
            "        input_data:\n",
            "          type: uri_file\n",
            "      outputs:\n",
            "        output_data:\n",
            "          type: uri_folder\n",
            "      command: python prep-data.py  --input_data ${{inputs.input_data}} --output_data\n",
            "        ${{outputs.output_data}}\n",
            "      environment: azureml:Churn-Proj-scikit-learn:0.1.1\n",
            "      code: /mnt/batch/tasks/shared/LS_root/mounts/clusters/ci05027a174bf34ac4bd/code/Users/Ramin_Vali/Customer_Churn/src\n",
            "      is_deterministic: true\n",
            "  train_model:\n",
            "    type: command\n",
            "    inputs:\n",
            "      training_data:\n",
            "        path: ${{parent.jobs.clean_data.outputs.output_data}}\n",
            "    outputs:\n",
            "      model_output: ${{parent.outputs.pipeline_job_trained_model}}\n",
            "    component:\n",
            "      $schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json\n",
            "      name: train_model\n",
            "      version: '1'\n",
            "      display_name: Train an XGBoost classifier model\n",
            "      type: command\n",
            "      inputs:\n",
            "        training_data:\n",
            "          type: uri_folder\n",
            "        learning_rate:\n",
            "          type: number\n",
            "          default: '0.01'\n",
            "        max_depth:\n",
            "          type: integer\n",
            "          default: '3'\n",
            "      outputs:\n",
            "        model_output:\n",
            "          type: mlflow_model\n",
            "      command: 'python train-model.py  --training_data ${{inputs.training_data}}  --learning_rate\n",
            "        ${{inputs.learning_rate}} --max_depth ${{inputs.max_depth}} --model_output\n",
            "        ${{outputs.model_output}} '\n",
            "      environment: azureml:Churn-Proj-scikit-learn:0.1.1\n",
            "      code: /mnt/batch/tasks/shared/LS_root/mounts/clusters/ci05027a174bf34ac4bd/code/Users/Ramin_Vali/Customer_Churn/src\n",
            "      is_deterministic: true\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(pipeline_job)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Update pipeline job. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1685108069410
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "display_name: customer_churn_classification\n",
            "type: pipeline\n",
            "inputs:\n",
            "  pipeline_job_input:\n",
            "    type: uri_file\n",
            "    path: azureml://subscriptions/733ee2ff-5a9c-42a2-8242-b8a500eb9f53/resourcegroups/rg-churn-pred-proj/workspaces/churn-pred-proj/datastores/workspaceblobstore/paths/LocalUpload/980708968c362ca31f4225d8576b9cab/churn.csv\n",
            "outputs:\n",
            "  pipeline_job_transformed_data:\n",
            "    mode: upload\n",
            "  pipeline_job_trained_model:\n",
            "    mode: upload\n",
            "jobs:\n",
            "  clean_data:\n",
            "    type: command\n",
            "    inputs:\n",
            "      input_data:\n",
            "        path: ${{parent.inputs.pipeline_job_input}}\n",
            "    outputs:\n",
            "      output_data: ${{parent.outputs.pipeline_job_transformed_data}}\n",
            "    component:\n",
            "      $schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json\n",
            "      name: prep_data\n",
            "      version: '1'\n",
            "      display_name: Prepare training data imbalanced sampling\n",
            "      type: command\n",
            "      inputs:\n",
            "        input_data:\n",
            "          type: uri_file\n",
            "      outputs:\n",
            "        output_data:\n",
            "          type: uri_folder\n",
            "      command: python prep-data.py  --input_data ${{inputs.input_data}} --output_data\n",
            "        ${{outputs.output_data}}\n",
            "      environment: azureml:Churn-Proj-scikit-learn:0.1.1\n",
            "      code: /mnt/batch/tasks/shared/LS_root/mounts/clusters/ci05027a174bf34ac4bd/code/Users/Ramin_Vali/Customer_Churn/src\n",
            "      is_deterministic: true\n",
            "  train_model:\n",
            "    type: command\n",
            "    inputs:\n",
            "      training_data:\n",
            "        path: ${{parent.jobs.clean_data.outputs.output_data}}\n",
            "    outputs:\n",
            "      model_output: ${{parent.outputs.pipeline_job_trained_model}}\n",
            "    component:\n",
            "      $schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json\n",
            "      name: train_model\n",
            "      version: '1'\n",
            "      display_name: Train an XGBoost classifier model\n",
            "      type: command\n",
            "      inputs:\n",
            "        training_data:\n",
            "          type: uri_folder\n",
            "        learning_rate:\n",
            "          type: number\n",
            "          default: '0.01'\n",
            "        max_depth:\n",
            "          type: integer\n",
            "          default: '3'\n",
            "      outputs:\n",
            "        model_output:\n",
            "          type: mlflow_model\n",
            "      command: 'python train-model.py  --training_data ${{inputs.training_data}}  --learning_rate\n",
            "        ${{inputs.learning_rate}} --max_depth ${{inputs.max_depth}} --model_output\n",
            "        ${{outputs.model_output}} '\n",
            "      environment: azureml:Churn-Proj-scikit-learn:0.1.1\n",
            "      code: /mnt/batch/tasks/shared/LS_root/mounts/clusters/ci05027a174bf34ac4bd/code/Users/Ramin_Vali/Customer_Churn/src\n",
            "      is_deterministic: true\n",
            "settings:\n",
            "  default_compute: azureml:cpu-cluster\n",
            "  default_datastore: azureml:workspaceblobstore\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# change the output mode\n",
        "pipeline_job.outputs.pipeline_job_transformed_data.mode = \"upload\"\n",
        "pipeline_job.outputs.pipeline_job_trained_model.mode = \"upload\"\n",
        "# set pipeline level compute\n",
        "pipeline_job.settings.default_compute = \"cpu-cluster\"\n",
        "# set pipeline level datastore\n",
        "pipeline_job.settings.default_datastore = \"workspaceblobstore\"\n",
        "\n",
        "# print the pipeline job again to review the changes\n",
        "print(pipeline_job)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Submit the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1685108082381
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32mUploading src (0.01 MBs): 100%|██████████| 7155/7155 [00:00<00:00, 196856.91it/s]\n",
            "\u001b[39m\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>pipeline_churn</td><td>olden_sheep_lzm6y4wfmb</td><td>pipeline</td><td>Preparing</td><td><a href=\"https://ml.azure.com/runs/olden_sheep_lzm6y4wfmb?wsid=/subscriptions/733ee2ff-5a9c-42a2-8242-b8a500eb9f53/resourcegroups/rg-churn-pred-proj/workspaces/churn-pred-proj&amp;tid=8544ec55-6367-4b6b-aa13-8537941ef1af\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
            ],
            "text/plain": [
              "PipelineJob({'inputs': {'pipeline_job_input': <azure.ai.ml.entities._job.pipeline._io.base.PipelineInput object at 0x7f1395fbe7d0>}, 'outputs': {'pipeline_job_transformed_data': <azure.ai.ml.entities._job.pipeline._io.base.PipelineOutput object at 0x7f1395fbd0c0>, 'pipeline_job_trained_model': <azure.ai.ml.entities._job.pipeline._io.base.PipelineOutput object at 0x7f1395fbf2e0>}, 'jobs': {}, 'component': PipelineComponent({'auto_increment_version': False, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': True, 'name': 'azureml_anonymous', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/ci05027a174bf34ac4bd/code/Users/Ramin_Vali/Customer_Churn', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f1395fbd7b0>, 'version': '1', 'latest_version': None, 'schema': None, 'type': 'pipeline', 'display_name': 'customer_churn_classification', 'is_deterministic': None, 'inputs': {'pipeline_job_input': {}}, 'outputs': {'pipeline_job_transformed_data': {}, 'pipeline_job_trained_model': {}}, 'yaml_str': None, 'other_parameter': {}, 'jobs': {'clean_data': Command({'parameters': {}, 'init': False, 'type': 'command', 'status': None, 'log_files': None, 'name': 'clean_data', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/ci05027a174bf34ac4bd/code/Users/Ramin_Vali/Customer_Churn', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f1395fbd930>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': None, 'experiment_name': None, 'compute': None, 'services': None, 'comment': None, 'job_inputs': {'input_data': '${{parent.inputs.pipeline_job_input}}'}, 'job_outputs': {'output_data': '${{parent.outputs.pipeline_job_transformed_data}}'}, 'inputs': {'input_data': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f1395fbdd20>}, 'outputs': {'output_data': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7f1395fbe140>}, 'component': 'azureml_anonymous:a8aff46e-a6de-4745-a42a-d93c999bf6cd', 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': None}, 'instance_id': '1f00c417-f25b-4d47-a441-32879eb5bc66', 'source': 'REMOTE.WORKSPACE.COMPONENT', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': None, 'environment_variables': {}, 'environment': None, 'resources': None, 'queue_settings': None, 'swept': False}), 'train_model': Command({'parameters': {}, 'init': False, 'type': 'command', 'status': None, 'log_files': None, 'name': 'train_model', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/ci05027a174bf34ac4bd/code/Users/Ramin_Vali/Customer_Churn', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f1395fbdae0>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': None, 'experiment_name': None, 'compute': None, 'services': None, 'comment': None, 'job_inputs': {'training_data': '${{parent.jobs.clean_data.outputs.output_data}}'}, 'job_outputs': {'model_output': '${{parent.outputs.pipeline_job_trained_model}}'}, 'inputs': {'training_data': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f1395fbfb50>}, 'outputs': {'model_output': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7f1395fbdd80>}, 'component': 'azureml_anonymous:2d283de9-4331-4f29-ba93-247034dac5f7', 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': None}, 'instance_id': '6508b1e1-d7c4-4308-a170-e4b1f76471f9', 'source': 'REMOTE.WORKSPACE.COMPONENT', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': None, 'environment_variables': {}, 'environment': None, 'resources': None, 'queue_settings': None, 'swept': False})}, 'job_types': {'command': 2}, 'job_sources': {'REMOTE.WORKSPACE.COMPONENT': 2}, 'source_job_id': None}), 'type': 'pipeline', 'status': 'Preparing', 'log_files': None, 'name': 'olden_sheep_lzm6y4wfmb', 'description': None, 'tags': {}, 'properties': {'azureml.DevPlatv2': 'true', 'azureml.DatasetAccessMode': 'Asset', 'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'MFE', 'runType': 'HTTP', 'azureml.parameters': '{}', 'azureml.continue_on_step_failure': 'True', 'azureml.continue_on_failed_optional_input': 'True', 'azureml.enforceRerun': 'False', 'azureml.defaultComputeName': 'cpu-cluster', 'azureml.defaultDataStoreName': 'workspaceblobstore', 'azureml.pipelineComponent': 'pipelinerun'}, 'print_as_yaml': True, 'id': '/subscriptions/733ee2ff-5a9c-42a2-8242-b8a500eb9f53/resourceGroups/rg-churn-pred-proj/providers/Microsoft.MachineLearningServices/workspaces/churn-pred-proj/jobs/olden_sheep_lzm6y4wfmb', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/ci05027a174bf34ac4bd/code/Users/Ramin_Vali/Customer_Churn', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f1395fbdc60>, 'serialize': <msrest.serialization.Serializer object at 0x7f1395fbea10>, 'display_name': 'customer_churn_classification', 'experiment_name': 'pipeline_churn', 'compute': None, 'services': {'Tracking': <azure.ai.ml.entities._job.job_service.JobService object at 0x7f1395fbe410>, 'Studio': <azure.ai.ml.entities._job.job_service.JobService object at 0x7f1395fbf4c0>}, 'settings': {}, 'identity': None, 'default_code': None, 'default_environment': None})"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# submit job to workspace\n",
        "pipeline_job = ml_client.jobs.create_or_update(\n",
        "    pipeline_job, experiment_name=\"pipeline_churn\"\n",
        ")\n",
        "pipeline_job"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "This takes at least 15-20 minutes to run through.\n",
        "Once the run is completed, you can see the logged metrics, ROC plot, Confusion Matrix, and feature importance plot. "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Optional:\n",
        "\n",
        "If you want to register the componets created in the workspace for other users, please run the cell below. Otherwise disregard it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "gather": {
          "logged": 1685046643662
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "prep_data = ml_client.components.create_or_update(prep_data)\n",
        "train_XGBoost = ml_client.components.create_or_update(train_XGBoost)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "gather": {
          "logged": 1685046685372
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "azure.ai.ml.entities._component.command_component.CommandComponent"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(prep_data)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Register Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1685111993788
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Model({'job_name': 'e4c67f0e-4090-43e6-9449-c271591d272d', 'is_anonymous': False, 'auto_increment_version': False, 'name': 'churn_model', 'description': 'Model created from run.', 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': '/subscriptions/733ee2ff-5a9c-42a2-8242-b8a500eb9f53/resourceGroups/rg-churn-pred-proj/providers/Microsoft.MachineLearningServices/workspaces/churn-pred-proj/models/churn_model/versions/2', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/ci05027a174bf34ac4bd/code/Users/Ramin_Vali/Customer_Churn', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f139607ce80>, 'serialize': <msrest.serialization.Serializer object at 0x7f139607c460>, 'version': '2', 'latest_version': None, 'path': 'azureml://subscriptions/733ee2ff-5a9c-42a2-8242-b8a500eb9f53/resourceGroups/rg-churn-pred-proj/workspaces/churn-pred-proj/datastores/workspaceartifactstore/paths/ExperimentRun/dcid.e4c67f0e-4090-43e6-9449-c271591d272d/model', 'datastore': None, 'utc_time_created': None, 'flavors': {'python_function': {'data': 'model.xgb', 'env': 'conda.yaml', 'loader_module': 'mlflow.xgboost', 'python_version': '3.8.16'}, 'xgboost': {'code': '', 'data': 'model.xgb', 'model_class': 'xgboost.sklearn.XGBClassifier', 'xgb_version': '1.7.5'}}, 'arm_type': 'model_version', 'type': 'mlflow_model'})"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from azure.ai.ml.entities import Model\n",
        "from azure.ai.ml.constants import ModelType\n",
        "\n",
        "\n",
        "job_name = \"e4c67f0e-4090-43e6-9449-c271591d272d\"\n",
        "\n",
        "run_model = Model(\n",
        "    path=f\"azureml://jobs/{job_name}/outputs/artifacts/paths/model/\",\n",
        "    name=\"churn_model\",\n",
        "    description=\"Model created from run.\",\n",
        "    type=AssetTypes.MLFLOW_MODEL,\n",
        ")\n",
        "# Uncomment after adding required details above\n",
        "ml_client.models.create_or_update(run_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1685112011284
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "creation_context:\n",
            "  created_at: '2023-05-26T14:38:28.269646+00:00'\n",
            "  created_by: Ramin Vali\n",
            "  created_by_type: User\n",
            "  last_modified_at: '2023-05-26T14:38:28.269646+00:00'\n",
            "  last_modified_by: Ramin Vali\n",
            "  last_modified_by_type: User\n",
            "description: Model created from run.\n",
            "flavors:\n",
            "  python_function:\n",
            "    data: model.xgb\n",
            "    env: conda.yaml\n",
            "    loader_module: mlflow.xgboost\n",
            "    python_version: 3.8.16\n",
            "  xgboost:\n",
            "    code: ''\n",
            "    data: model.xgb\n",
            "    model_class: xgboost.sklearn.XGBClassifier\n",
            "    xgb_version: 1.7.5\n",
            "id: azureml:/subscriptions/733ee2ff-5a9c-42a2-8242-b8a500eb9f53/resourceGroups/rg-churn-pred-proj/providers/Microsoft.MachineLearningServices/workspaces/churn-pred-proj/models/churn_model/versions/1\n",
            "job_name: e4c67f0e-4090-43e6-9449-c271591d272d\n",
            "name: churn_model\n",
            "path: azureml://subscriptions/733ee2ff-5a9c-42a2-8242-b8a500eb9f53/resourceGroups/rg-churn-pred-proj/workspaces/churn-pred-proj/datastores/workspaceartifactstore/paths/ExperimentRun/dcid.e4c67f0e-4090-43e6-9449-c271591d272d/model\n",
            "properties: {}\n",
            "tags: {}\n",
            "type: mlflow_model\n",
            "version: '1'\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model_example = ml_client.models.get(name=\"churn_model\", version=\"1\")\n",
        "print(model_example)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Define and create an endpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "gather": {
          "logged": 1685128899308
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import ManagedOnlineEndpoint\n",
        "import datetime\n",
        "\n",
        "online_endpoint_name = \"endpoint-\" + datetime.datetime.now().strftime(\"%m%d%H%M%f\")\n",
        "\n",
        "# create an online endpoint\n",
        "endpoint = ManagedOnlineEndpoint(\n",
        "    name=online_endpoint_name,\n",
        "    description=\"Online endpoint for MLflow customer churn model\",\n",
        "    auth_mode=\"key\",\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Create the endpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "gather": {
          "logged": 1685129026747
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ManagedOnlineEndpoint({'public_network_access': 'Enabled', 'provisioning_state': 'Succeeded', 'scoring_uri': 'https://endpoint-05261921266135.eastus.inference.ml.azure.com/score', 'openapi_uri': 'https://endpoint-05261921266135.eastus.inference.ml.azure.com/swagger.json', 'name': 'endpoint-05261921266135', 'description': 'Online endpoint for MLflow customer churn model', 'tags': {}, 'properties': {'azureml.onlineendpointid': '/subscriptions/733ee2ff-5a9c-42a2-8242-b8a500eb9f53/resourcegroups/rg-churn-pred-proj/providers/microsoft.machinelearningservices/workspaces/churn-pred-proj/onlineendpoints/endpoint-05261921266135', 'AzureAsyncOperationUri': 'https://management.azure.com/subscriptions/733ee2ff-5a9c-42a2-8242-b8a500eb9f53/providers/Microsoft.MachineLearningServices/locations/eastus/mfeOperationsStatus/oe:124b81bd-ce3b-4e78-acb1-ece848a87681:136c51ee-f935-4509-be4e-2bb0ee581032?api-version=2022-02-01-preview'}, 'print_as_yaml': True, 'id': '/subscriptions/733ee2ff-5a9c-42a2-8242-b8a500eb9f53/resourceGroups/rg-churn-pred-proj/providers/Microsoft.MachineLearningServices/workspaces/churn-pred-proj/onlineEndpoints/endpoint-05261921266135', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/ci05027a174bf34ac4bd/code/Users/Ramin_Vali/Customer_Churn', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f1392580070>, 'auth_mode': 'key', 'location': 'eastus', 'identity': <azure.ai.ml.entities._credentials.IdentityConfiguration object at 0x7f13925056c0>, 'traffic': {}, 'mirror_traffic': {}, 'kind': 'Managed'})"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ml_client.begin_create_or_update(endpoint).result()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "This step take some time. Please wait until the notification pops up, or you can see the endpoint created successfully under the endpoints tab."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Configuring the deployment\n",
        "\n",
        "We already have our MLflow model to deploy. Given it is an MLflow model, we do not need to supply an environment. Normal models require the model and the environment registered separably. Need to be careful with instance type. I do not have access to all of them because of my tier, the current selection won't work on very large models, but is good for the demonstration purposes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "gather": {
          "logged": 1685129832441
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import Model, ManagedOnlineDeployment\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "# Getting the registered MLflow model. Need to rpvide name and version. These are available under model tab.\n",
        "model = ml_client.models.get(name='churn_model', version=2)\n",
        "\n",
        "# Configure a blue deployment\n",
        "blue_deployment = ManagedOnlineDeployment(\n",
        "    name=\"blue\",\n",
        "    endpoint_name=online_endpoint_name,\n",
        "    model=model,\n",
        "    instance_type=\"Standard_E2s_v3\",\n",
        "    instance_count=1,\n",
        ")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Deploying the model to the online endpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "gather": {
          "logged": 1685133923668
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Check: endpoint endpoint-05261921266135 exists\n",
            "data_collector is not a known attribute of class <class 'azure.ai.ml._restclient.v2022_02_01_preview.models._models_py3.ManagedOnlineDeployment'> and will be ignored\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "..............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................."
          ]
        },
        {
          "ename": "HttpResponseError",
          "evalue": "(None) InternalServerError: Internal error. Please see troubleshooting guide, available here: https://aka.ms/oe-tsg#error-internalservererror\nCode: None\nMessage: InternalServerError: Internal error. Please see troubleshooting guide, available here: https://aka.ms/oe-tsg#error-internalservererror\nException Details:\t(None) InternalServerError: Internal error. Please see troubleshooting guide, available here: https://aka.ms/oe-tsg#error-internalservererror\n\tThe build log is available in the workspace blob store \"churnprestoragec3697ee7e\" under the path \"/azureml/ImageLogs/496008f2-073a-4997-80cc-0df89a887b24/build.log\"\n\tCode: None\n\tMessage: InternalServerError: Internal error. Please see troubleshooting guide, available here: https://aka.ms/oe-tsg#error-internalservererror\n\tThe build log is available in the workspace blob store \"churnprestoragec3697ee7e\" under the path \"/azureml/ImageLogs/496008f2-073a-4997-80cc-0df89a887b24/build.log\"",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOperationFailed\u001b[0m                           Traceback (most recent call last)",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/polling/base_polling.py:466\u001b[0m, in \u001b[0;36mLROBasePolling.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 466\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m BadStatus \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/polling/base_polling.py:500\u001b[0m, in \u001b[0;36mLROBasePolling._poll\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _failed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus()):\n\u001b[0;32m--> 500\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OperationFailed(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOperation failed or canceled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    502\u001b[0m final_get_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_operation\u001b[38;5;241m.\u001b[39mget_final_get_url(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pipeline_response)\n",
            "\u001b[0;31mOperationFailed\u001b[0m: Operation failed or canceled",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mHttpResponseError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[57], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mml_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monline_deployments\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin_create_or_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblue_deployment\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/polling/_poller.py:230\u001b[0m, in \u001b[0;36mLROPoller.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresult\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PollingReturnType:\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;124;03m\"\"\"Return the result of the long running operation, or\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;124;03m    the result available after the specified timeout.\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;124;03m    :raises ~azure.core.exceptions.HttpResponseError: Server problem with the query.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 230\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_polling_method\u001b[38;5;241m.\u001b[39mresource()\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/tracing/decorator.py:76\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m span_impl_type \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mtracing_implementation()\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/polling/_poller.py:249\u001b[0m, in \u001b[0;36mLROPoller.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_thread\u001b[38;5;241m.\u001b[39mjoin(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;66;03m# Let's handle possible None in forgiveness here\u001b[39;00m\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;66;03m# https://github.com/python/mypy/issues/8165\u001b[39;00m\n\u001b[0;32m--> 249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# Was None\u001b[39;00m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/polling/_poller.py:169\u001b[0m, in \u001b[0;36mLROPoller._start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;124;03m\"\"\"Start the long running operation.\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03mOn completion, runs any callbacks.\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03m:param callable update_cmd: The API request to check the status of\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;124;03m the operation.\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_polling_method\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m AzureError \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m error\u001b[38;5;241m.\u001b[39mcontinuation_token:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/polling/base_polling.py:481\u001b[0m, in \u001b[0;36mLROBasePolling.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    474\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HttpResponseError(\n\u001b[1;32m    475\u001b[0m         response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pipeline_response\u001b[38;5;241m.\u001b[39mhttp_response,\n\u001b[1;32m    476\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(err),\n\u001b[1;32m    477\u001b[0m         error\u001b[38;5;241m=\u001b[39merr,\n\u001b[1;32m    478\u001b[0m     )\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OperationFailed \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 481\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HttpResponseError(response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pipeline_response\u001b[38;5;241m.\u001b[39mhttp_response, error\u001b[38;5;241m=\u001b[39merr)\n",
            "\u001b[0;31mHttpResponseError\u001b[0m: (None) InternalServerError: Internal error. Please see troubleshooting guide, available here: https://aka.ms/oe-tsg#error-internalservererror\nCode: None\nMessage: InternalServerError: Internal error. Please see troubleshooting guide, available here: https://aka.ms/oe-tsg#error-internalservererror\nException Details:\t(None) InternalServerError: Internal error. Please see troubleshooting guide, available here: https://aka.ms/oe-tsg#error-internalservererror\n\tThe build log is available in the workspace blob store \"churnprestoragec3697ee7e\" under the path \"/azureml/ImageLogs/496008f2-073a-4997-80cc-0df89a887b24/build.log\"\n\tCode: None\n\tMessage: InternalServerError: Internal error. Please see troubleshooting guide, available here: https://aka.ms/oe-tsg#error-internalservererror\n\tThe build log is available in the workspace blob store \"churnprestoragec3697ee7e\" under the path \"/azureml/ImageLogs/496008f2-073a-4997-80cc-0df89a887b24/build.log\""
          ]
        }
      ],
      "source": [
        "ml_client.online_deployments.begin_create_or_update(blue_deployment).result()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "The deployment of the model may take 10-15 minutes. <mark>PLEASE WAIT</mark> for deployment to complete before continuing. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "gather": {
          "logged": 1685128525892
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<azure.core.polling._poller.LROPoller at 0x7f1395e8e8c0>"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "................."
          ]
        }
      ],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "100% of traffic directed to blue deployment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "# blue deployment takes 100 traffic\n",
        "endpoint.traffic = {\"blue\": 100}\n",
        "ml_client.begin_create_or_update(endpoint).result()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Please wait until this update finishes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# test the blue deployment with some sample data\n",
        "response = ml_client.online_endpoints.invoke(\n",
        "    endpoint_name=online_endpoint_name,\n",
        "    deployment_name=\"blue\",\n",
        "    request_file=\"sample_data.json\",\n",
        ")\n",
        "\n",
        "if response[1]=='1':\n",
        "    print(\"Customer Will Churn\")\n",
        "else:\n",
        "    print (\"Customer Will NOT Churn\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ml_client.online_endpoints.begin_delete(name=online_endpoint_name)"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - SDK v2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
